{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ec91c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Phase 3 – I'm building a baseline model.\n",
    "# ================================================================\n",
    "# I'm keeping it simple here, just using pandas and scikit-learn.\n",
    "# I'll add a lot of comments so it's easy to see what I'm doing.\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "# I'll need these for the machine learning part.\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.model_selection import TimeSeriesSplit, cross_val_score\n",
    "from sklearn.impute import SimpleImputer # I need this to handle missing values.\n",
    "\n",
    "# 1. I'll load the data first.\n",
    "clean_path = Path(\"../data/processed/clean_hdb.csv\")  # I might need to change this path if I move the notebook.\n",
    "df = pd.read_csv(clean_path, parse_dates=[\"sale_date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ca22577",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I need to make sure 'sale_date' is a datetime object for sorting.\n",
    "df['sale_date'] = pd.to_datetime(df['sale_date'])\n",
    "\n",
    "# --- I'll do some feature engineering and preprocessing based on what I saw in df.info(). ---\n",
    "\n",
    "# I need to identify which columns to drop.\n",
    "cols_to_drop_pre_encoding = [\n",
    "    '_id',        # This is just an identifier.\n",
    "    'month',      # This is redundant because I have 'sale_month'.\n",
    "    'town',       # This is redundant if I already have the town_X columns.\n",
    "    'flat_type',  # Same for this one.\n",
    "    'block',      # This has too many unique values for linear regression.\n",
    "    'street_name' # This one too.\n",
    "]\n",
    "# Now I'll drop them if they exist.\n",
    "df = df.drop(columns=[col for col in cols_to_drop_pre_encoding if col in df.columns])\n",
    "\n",
    "# Now I need to find the remaining object columns to one-hot encode.\n",
    "# I think it's just 'storey_range' and 'flat_model'.\n",
    "categorical_cols_to_encode = [\n",
    "    c for c in df.columns if df[c].dtype == 'object'\n",
    "]\n",
    "\n",
    "# And now I'll apply the one-hot encoding.\n",
    "if categorical_cols_to_encode:\n",
    "    df = pd.get_dummies(df, columns=categorical_cols_to_encode, drop_first=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd2c70dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- I need to handle the missing values (NaNs). ---\n",
    "# I'll use median imputation since it's robust to outliers.\n",
    "numerical_cols_with_nans = ['lease_remaining_years', 'flat_age']\n",
    "\n",
    "# I'll create an imputer.\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "# SimpleImputer gives me a numpy array, so I'll convert it back to a DataFrame.\n",
    "df[numerical_cols_with_nans] = imputer.fit_transform(df[numerical_cols_with_nans])\n",
    "# I can check for NaNs after imputation with print(\"\\nColumns with NaNs after imputation:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5280cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------------------------------\n",
    "# 3.1  I'll do a time-based train/test split.\n",
    "# ----------------------------------------------------------------\n",
    "\n",
    "df = df.sort_values(\"sale_year\")          # 3.1.1 – I need to make sure it's in chronological order.\n",
    "\n",
    "train = df[df.sale_year <= 2023]          # 3.1.2 – I'll train on everything up to 2023.\n",
    "test  = df[df.sale_year >= 2024]          # And use the last two years as a hold-out set.\n",
    "\n",
    "# I should drop any obvious target leakage columns.\n",
    "y_col = \"resale_price\"\n",
    "X_cols = [c for c in df.columns\n",
    "          if c not in [y_col, \"price_per_sqm\", \"sale_date\"]]\n",
    "\n",
    "X_train, y_train = train[X_cols], train[y_col]   # 3.1.3\n",
    "X_test , y_test  = test [X_cols], test [y_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd8add48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================================\n",
    "# My QA Plan - I'm implementing some checks that ChatGPT suggested.\n",
    "# ================================================================\n",
    "\n",
    "print(\"\\n--- QA Checks ---\")\n",
    "\n",
    "# 1. I'll check for column parity to make sure I didn't mess up the train/test columns.\n",
    "missing_in_train = set(X_test.columns) - set(X_train.columns)\n",
    "missing_in_test = set(X_train.columns) - set(X_test.columns)\n",
    "\n",
    "if missing_in_train or missing_in_test:\n",
    "    print(f\"WARNING: Column mismatch between X_train and X_test!\")\n",
    "    if missing_in_train:\n",
    "        print(f\"  Columns in X_test but not in X_train: {missing_in_train}\")\n",
    "    if missing_in_test:\n",
    "        print(f\"  Columns in X_train but not in X_test: {missing_in_test}\")\n",
    "    # This is a critical error, so I might want to assert False here.\n",
    "else:\n",
    "    print(\"✅ Column parity: X_train and X_test have identical columns.\")\n",
    "\n",
    "\n",
    "# 2. I need to make sure there are no NaNs in the model input.\n",
    "train_nans = X_train.isna().sum().sum()\n",
    "test_nans = X_test.isna().sum().sum()\n",
    "if train_nans == 0 and test_nans == 0:\n",
    "    print(\"✅ No NaNs found in X_train or X_test.\")\n",
    "else:\n",
    "    print(f\"❌ NaNs found! X_train has {train_nans} NaNs, X_test has {test_nans} NaNs.\")\n",
    "\n",
    "\n",
    "# 3. I'll check the test-set size.\n",
    "test_share = len(test) / len(df)\n",
    "print(f\"✅ Test set share: {test_share:.2%}\")\n",
    "if test_share < 0.05: # I'll use ChatGPT's 5% threshold.\n",
    "    print(\"   WARNING: Test set is less than 5% of total data, metrics might be noisy.\")\n",
    "elif test_share > 0.30: # This is an arbitrary upper limit I can adjust.\n",
    "    print(\"   Note: Test set is quite large, reducing training data significantly.\")\n",
    "\n",
    "\n",
    "# 4. I'll check the condition number for multicollinearity.\n",
    "try:\n",
    "    from numpy.linalg import cond\n",
    "    # I'll convert to float to avoid any potential integer overflow.\n",
    "    X_train_numeric = X_train.select_dtypes(include=np.number).to_numpy()\n",
    "    if X_train_numeric.size > 0: # I'll only compute this if there are numeric columns.\n",
    "        condition_number = cond(X_train_numeric)\n",
    "        print(f\"✅ Condition number for X_train: {condition_number:.2e}\")\n",
    "        if condition_number > 1e8:\n",
    "            print(\"   WARNING: High condition number indicates severe multicollinearity.\")\n",
    "            print(\"            This affects coefficient interpretability but usually not prediction accuracy.\")\n",
    "    else:\n",
    "        print(\"ℹ️ No numeric columns found in X_train to compute condition number.\")\n",
    "\n",
    "except ImportError:\n",
    "    print(\"ℹ️ numpy.linalg.cond not available. Skipping multicollinearity check.\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ Error computing condition number: {e}\")\n",
    "\n",
    "\n",
    "# 5. I'm curious, so I'll re-run the metrics with a log-transformed target.\n",
    "# This isn't a bug check, just something I want to explore.\n",
    "try:\n",
    "    lr_log = LinearRegression()\n",
    "    # I'll apply a log1p transformation to y_train and y_test.\n",
    "    y_train_log = np.log1p(y_train)\n",
    "    y_test_log = np.log1p(y_test)\n",
    "\n",
    "    lr_log.fit(X_train, y_train_log)\n",
    "    preds_log = lr_log.predict(X_test)\n",
    "\n",
    "    # I need to inverse transform the predictions to calculate MAE and RMSE.\n",
    "    preds_original_scale = np.expm1(preds_log)\n",
    "\n",
    "    mae_log_transformed = mean_absolute_error(y_test, preds_original_scale)\n",
    "    rmse_log_transformed = np.sqrt(mean_squared_error(y_test, preds_original_scale))\n",
    "\n",
    "    print(f\"\\n--- Log-transformed target metrics (for comparison) ---\")\n",
    "    print(f\"MAE (log-transformed): {mae_log_transformed:.1f}\")\n",
    "    print(f\"RMSE (log-transformed): {rmse_log_transformed:.1f}\")\n",
    "    if mae_log_transformed < mae:\n",
    "        print(\"   Note: Log-transformation slightly improved MAE.\")\n",
    "    else:\n",
    "        print(\"   Note: Log-transformation did not improve MAE for this baseline.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"\\n❌ Error during log-target metric calculation: {e}\")\n",
    "\n",
    "\n",
    "print(\"--- QA Checks Complete ---\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d73cbd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------------------------------\n",
    "# 3.2  My baseline Linear Regression.\n",
    "# ----------------------------------------------------------------\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "preds = lr.predict(X_test)\n",
    "mae  = mean_absolute_error(y_test, preds)\n",
    "mse = mean_squared_error(y_test, preds)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "results = pd.DataFrame({\n",
    "    \"model\": [\"LinearRegression\"],\n",
    "    \"MAE_SGD\": [round(mae, 1)],\n",
    "    \"RMSE_SGD\": [round(rmse, 1)],\n",
    "})\n",
    "report_path = Path(\"../reports/baseline_metrics.csv\")\n",
    "results.to_csv(report_path, index=False)\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37928174",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------------------------------\n",
    "# 3.3  I'll do a quick time-series cross-validation on the train set.\n",
    "#      (5 splits, with an expanding window)\n",
    "# ----------------------------------------------------------------\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "cv_mae = -cross_val_score(lr, X_train, y_train,\n",
    "                          cv=tscv,\n",
    "                          scoring=\"neg_mean_absolute_error\")\n",
    "print(f\"CV MAE (mean ± std): {cv_mae.mean():.0f} ± {cv_mae.std():.0f} SGD\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6633ec70",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Here's what I'm doing:\n",
    "\n",
    "    •   Chronological Split: I'm setting up a time-based train/test split. I'll train the model on data up to 2023 and predict prices for 2024 and later. This is how it would work in the real world, so I'm not accidentally leaking future data into my training.\n",
    "\n",
    "    •   Feature Engineering & Selection:\n",
    "        •   I'm excluding the target variable, 'resale_price'.\n",
    "        •   I'm also excluding 'price_per_sqm' to avoid target leakage, since it's derived from 'resale_price'.\n",
    "        •   I'm dropping highly cardinal string identifiers like '_id', 'block', and 'street_name' because they aren't great for linear regression without a lot of work.\n",
    "        •   I'm excluding raw date strings and just using the numerical year and month features.\n",
    "        •   I'm using the one-hot encoded columns I already have and encoding any other categorical strings.\n",
    "        •   I'm imputing missing numerical values with the median.\n",
    "\n",
    "    •   Baseline Model - Linear Regression: I'm using a simple Linear Regression model. I chose it because it's simple and doesn't have any hyperparameters, so it gives me a clear baseline to compare against more complex models.\n",
    "\n",
    "    •   My metrics:\n",
    "        •   MAE (Mean Absolute Error): This is the average absolute difference between my predicted and actual prices. It's easy to understand.\n",
    "        •   RMSE (Root Mean Squared Error): This penalizes larger errors more heavily. It's a good way to compare different models.\n",
    "'''\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hdb-price-predictor",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

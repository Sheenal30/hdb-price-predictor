{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9ec91c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Phase 3 – Baseline modelling\n",
    "# ================================================================\n",
    "# Simple > complex.  Everything here is pure pandas / scikit-learn.\n",
    "# lots of #comments so anyone can tweak ranges or models.\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "# ML\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.model_selection import TimeSeriesSplit, cross_val_score\n",
    "from sklearn.impute import SimpleImputer # Import SimpleImputer\n",
    "\n",
    "# 1. Load\n",
    "clean_path = Path(\"../data/processed/clean_hdb.csv\")  # adjust if notebook lives elsewhere\n",
    "df = pd.read_csv(clean_path, parse_dates=[\"sale_date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0ca22577",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'sale_date' to datetime if it's not already (important for sorting if using date directly)\n",
    "df['sale_date'] = pd.to_datetime(df['sale_date'])\n",
    "\n",
    "# --- Feature Engineering / Preprocessing based on your df.info() ---\n",
    "\n",
    "# Identify columns to drop (identifiers, redundant string columns, highly cardinal strings)\n",
    "cols_to_drop_pre_encoding = [\n",
    "    '_id',        # Identifier\n",
    "    'month',      # Redundant with 'sale_month' and is a string\n",
    "    'town',       # Redundant if town_X columns are already present and used\n",
    "    'flat_type',  # Redundant if flat_type_X columns are already present and used\n",
    "    'block',      # Highly cardinal string, not suitable for direct encoding in Linear Regression\n",
    "    'street_name' # Highly cardinal string, not suitable for direct encoding in Linear Regression\n",
    "]\n",
    "# Drop these columns if they exist in the DataFrame\n",
    "df = df.drop(columns=[col for col in cols_to_drop_pre_encoding if col in df.columns])\n",
    "\n",
    "# Identify remaining object Dtype columns that need one-hot encoding\n",
    "# Based on your df.info(), these are likely 'storey_range' and 'flat_model'\n",
    "categorical_cols_to_encode = [\n",
    "    c for c in df.columns if df[c].dtype == 'object'\n",
    "]\n",
    "\n",
    "# Apply one-hot encoding to the remaining specified categorical columns\n",
    "if categorical_cols_to_encode:\n",
    "    df = pd.get_dummies(df, columns=categorical_cols_to_encode, drop_first=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fd2c70dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Handle Missing Values (NaN) ---\n",
    "# Check for NaNs before imputation (optional, for verification)\n",
    "# print(\"Columns with NaNs before imputation:\")\n",
    "# print(df.isnull().sum()[df.isnull().sum() > 0])\n",
    "\n",
    "# Impute missing values for numerical columns.\n",
    "# Based on your df.info(), these are 'lease_remaining_years' and 'flat_age'.\n",
    "# We will use median imputation as it's robust to outliers.\n",
    "numerical_cols_with_nans = ['lease_remaining_years', 'flat_age']\n",
    "\n",
    "# Create an imputer\n",
    "# You can use strategy='mean', 'median', or 'most_frequent'\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "\n",
    "# Apply imputation. It's best to apply this to the full DataFrame before splitting\n",
    "# to ensure consistent imputation across train and test sets.\n",
    "# SimpleImputer returns a numpy array, so we convert it back to a DataFrame\n",
    "# and preserve column names.\n",
    "df[numerical_cols_with_nans] = imputer.fit_transform(df[numerical_cols_with_nans])\n",
    "\n",
    "# Verify no more NaNs in these columns (optional)\n",
    "# print(\"\\nColumns with NaNs after imputation:\")\n",
    "# print(df.isnull().sum()[df.isnull().sum() > 0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d5280cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------------------------------\n",
    "# 3 .1  Time-based train / test split\n",
    "# ----------------------------------------------------------------\n",
    "\n",
    "df = df.sort_values(\"sale_year\")          # 3 .1 .1 – chronological order\n",
    "\n",
    "train = df[df.sale_year <= 2023]          # 3 .1 .2 – up to 2023 inclusive\n",
    "test  = df[df.sale_year >= 2024]          # last two years = hold-out\n",
    "\n",
    "# drop obvious target leakage columns\n",
    "y_col = \"resale_price\"\n",
    "X_cols = [c for c in df.columns\n",
    "          if c not in [y_col, \"price_per_sqm\", \"sale_date\"]]\n",
    "\n",
    "X_train, y_train = train[X_cols], train[y_col]   # 3 .1 .3\n",
    "X_test , y_test  = test [X_cols], test [y_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bd8add48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- QA Checks ---\n",
      "✅ Column parity: X_train and X_test have identical columns.\n",
      "✅ No NaNs found in X_train or X_test.\n",
      "✅ Test set share: 4.50%\n",
      "   WARNING: Test set is less than 5% of total data, metrics might be noisy.\n",
      "✅ Condition number for X_train: 3.85e+04\n",
      "\n",
      "--- Log-transformed target metrics (for comparison) ---\n",
      "MAE (log-transformed): 81783.3\n",
      "RMSE (log-transformed): 109381.3\n",
      "   Note: Log-transformation slightly improved MAE.\n",
      "--- QA Checks Complete ---\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ================================================================\n",
    "# QA Plan - Implementing ChatGPT's checks\n",
    "# ================================================================\n",
    "\n",
    "print(\"\\n--- QA Checks ---\")\n",
    "\n",
    "# 1. Column parity (Mis-aligned train/test columns after encoding)\n",
    "missing_in_train = set(X_test.columns) - set(X_train.columns)\n",
    "missing_in_test = set(X_train.columns) - set(X_test.columns)\n",
    "\n",
    "if missing_in_train or missing_in_test:\n",
    "    print(f\"WARNING: Column mismatch between X_train and X_test!\")\n",
    "    if missing_in_train:\n",
    "        print(f\"  Columns in X_test but not in X_train: {missing_in_train}\")\n",
    "    if missing_in_test:\n",
    "        print(f\"  Columns in X_train but not in X_test: {missing_in_test}\")\n",
    "    # For a critical error, you might want to assert False or raise an error here\n",
    "    # assert not missing_in_train and not missing_in_test, \"Column mismatch detected!\"\n",
    "else:\n",
    "    print(\"✅ Column parity: X_train and X_test have identical columns.\")\n",
    "\n",
    "\n",
    "# 2. No NaNs in model input\n",
    "train_nans = X_train.isna().sum().sum()\n",
    "test_nans = X_test.isna().sum().sum()\n",
    "if train_nans == 0 and test_nans == 0:\n",
    "    print(\"✅ No NaNs found in X_train or X_test.\")\n",
    "else:\n",
    "    print(f\"❌ NaNs found! X_train has {train_nans} NaNs, X_test has {test_nans} NaNs.\")\n",
    "\n",
    "\n",
    "# 3. Check test-set size\n",
    "test_share = len(test) / len(df)\n",
    "print(f\"✅ Test set share: {test_share:.2%}\")\n",
    "if test_share < 0.05: # Using ChatGPT's 5% threshold\n",
    "    print(\"   WARNING: Test set is less than 5% of total data, metrics might be noisy.\")\n",
    "elif test_share > 0.30: # Arbitrary upper limit, adjust as needed\n",
    "    print(\"   Note: Test set is quite large, reducing training data significantly.\")\n",
    "\n",
    "\n",
    "# 4. Condition number for multicollinearity\n",
    "try:\n",
    "    from numpy.linalg import cond\n",
    "    # Convert to float to avoid potential integer overflow for large numbers\n",
    "    # Ensure all columns are numeric after all processing\n",
    "    X_train_numeric = X_train.select_dtypes(include=np.number).to_numpy()\n",
    "    if X_train_numeric.size > 0: # Check if there are numeric columns to compute cond on\n",
    "        condition_number = cond(X_train_numeric)\n",
    "        print(f\"✅ Condition number for X_train: {condition_number:.2e}\")\n",
    "        if condition_number > 1e8:\n",
    "            print(\"   WARNING: High condition number indicates severe multicollinearity.\")\n",
    "            print(\"            This affects coefficient interpretability but usually not prediction accuracy.\")\n",
    "    else:\n",
    "        print(\"ℹ️ No numeric columns found in X_train to compute condition number.\")\n",
    "\n",
    "except ImportError:\n",
    "    print(\"ℹ️ numpy.linalg.cond not available. Skipping multicollinearity check.\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ Error computing condition number: {e}\")\n",
    "\n",
    "\n",
    "# 5. Re-run metrics with log-target for curiosity (Optional, but good for exploration)\n",
    "# This isn't a \"bug check\" but a recommended exploration\n",
    "try:\n",
    "    lr_log = LinearRegression()\n",
    "    # Apply log1p transformation to y_train and y_test\n",
    "    y_train_log = np.log1p(y_train)\n",
    "    y_test_log = np.log1p(y_test)\n",
    "\n",
    "    lr_log.fit(X_train, y_train_log)\n",
    "    preds_log = lr_log.predict(X_test)\n",
    "\n",
    "    # Inverse transform predictions for MAE and RMSE calculation\n",
    "    preds_original_scale = np.expm1(preds_log)\n",
    "\n",
    "    mae_log_transformed = mean_absolute_error(y_test, preds_original_scale)\n",
    "    rmse_log_transformed = np.sqrt(mean_squared_error(y_test, preds_original_scale))\n",
    "\n",
    "    print(f\"\\n--- Log-transformed target metrics (for comparison) ---\")\n",
    "    print(f\"MAE (log-transformed): {mae_log_transformed:.1f}\")\n",
    "    print(f\"RMSE (log-transformed): {rmse_log_transformed:.1f}\")\n",
    "    if mae_log_transformed < mae:\n",
    "        print(\"   Note: Log-transformation slightly improved MAE.\")\n",
    "    else:\n",
    "        print(\"   Note: Log-transformation did not improve MAE for this baseline.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"\\n❌ Error during log-target metric calculation: {e}\")\n",
    "\n",
    "\n",
    "print(\"--- QA Checks Complete ---\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5d73cbd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              model  MAE_SGD  RMSE_SGD\n",
      "0  LinearRegression  83733.9  119830.1\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------------------------------------------\n",
    "# 3 .2  Baseline Linear Regression\n",
    "# ----------------------------------------------------------------\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "preds = lr.predict(X_test)\n",
    "mae  = mean_absolute_error(y_test, preds)\n",
    "mse = mean_squared_error(y_test, preds)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "results = pd.DataFrame({\n",
    "    \"model\": [\"LinearRegression\"],\n",
    "    \"MAE_SGD\": [round(mae, 1)],\n",
    "    \"RMSE_SGD\": [round(rmse, 1)],\n",
    "})\n",
    "report_path = Path(\"../reports/baseline_metrics.csv\")\n",
    "results.to_csv(report_path, index=False)\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "37928174",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV MAE (mean ± std): 73752 ± 17389 SGD\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------------------------------------------\n",
    "# 3 .3  Quick Time-series cross-validation on the train set\n",
    "#     (5 splits, expanding window)\n",
    "# ----------------------------------------------------------------\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "cv_mae = -cross_val_score(lr, X_train, y_train,\n",
    "                          cv=tscv,\n",
    "                          scoring=\"neg_mean_absolute_error\")\n",
    "print(f\"CV MAE (mean ± std): {cv_mae.mean():.0f} ± {cv_mae.std():.0f} SGD\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6633ec70",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "What’s happening:\n",
    "\n",
    "    •   Chronological Split: We establish a time-based train/test split. The model trains on data up to 2023 inclusive and predicts prices for 2024 and onwards. This setup accurately mimics real-world deployment scenarios, ensuring no future data \"leaks\" into the training process.\n",
    "\n",
    "    •   Feature Engineering & Selection:\n",
    "        •   The target variable, 'resale_price', is excluded.\n",
    "        •   'price_per_sqm' is also excluded to prevent target leakage, as it's directly derived from 'resale_price'.\n",
    "        •   Highly cardinal string identifiers like '_id', 'block', and 'street_name' are dropped, as they are generally not suitable for direct use in linear regression without complex feature engineering.\n",
    "        •   Raw date strings ('month', 'sale_date') are excluded, relying instead on numerical year and month features.\n",
    "        •   Existing one-hot encoded columns (like 'town_X', 'flat_type_X') are utilized, and any remaining categorical strings ('storey_range', 'flat_model') are one-hot encoded to convert them into a numerical format suitable for the model.\n",
    "        •   Missing numerical values in 'lease_remaining_years' and 'flat_age' are imputed using the median strategy for robustness.\n",
    "\n",
    "    •   Baseline Model - Linear Regression: We use a straightforward Linear Regression model. This choice is deliberate due to its simplicity and lack of hyperparameters, providing a clear and fast baseline MAE (Mean Absolute Error) and RMSE (Root Mean Squared Error) to evaluate against more complex models (like tree-based methods) in subsequent phases.\n",
    "\n",
    "    •   Metrics Explained:\n",
    "        •   MAE (Mean Absolute Error): Represents the average absolute difference between predicted and actual prices, offering an easily interpretable measure of typical prediction error in dollar terms.\n",
    "        •   RMSE (Root Mean Squared Error): Penalizes larger prediction errors more heavily than smaller ones. It's a commonly used metric for regression that provides a good comparative measure across models.\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08612b5b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hdb-price-predictor",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

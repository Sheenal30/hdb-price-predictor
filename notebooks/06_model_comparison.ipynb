{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43eb58cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- 1. I'll set up and load the data. ---\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import lightgbm as lgb # I'll import LightGBM.\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import joblib\n",
    "import warnings\n",
    "\n",
    "# I'll suppress warnings for a cleaner output.\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# I need to set up my project root.\n",
    "try:\n",
    "    PROJECT_ROOT = Path(__file__).resolve().parent.parent\n",
    "except NameError:\n",
    "    PROJECT_ROOT = Path('.').resolve().parent\n",
    "\n",
    "# I'll load the processed data.\n",
    "try:\n",
    "    X_train = pd.read_csv(PROJECT_ROOT / \"data/processed/X_train_processed.csv\")\n",
    "    y_train = pd.read_csv(PROJECT_ROOT / \"data/processed/y_train_processed.csv\").squeeze()\n",
    "    X_test = pd.read_csv(PROJECT_ROOT / \"data/processed/X_test_processed.csv\")\n",
    "    y_test = pd.read_csv(PROJECT_ROOT / \"data/processed/y_test_processed.csv\").squeeze()\n",
    "    print(\"Processed data loaded successfully.\")\n",
    "    print(f\"X_train shape: {X_train.shape}, y_train shape: {y_train.shape}\")\n",
    "    print(f\"X_test shape: {X_test.shape}, y_test shape: {y_test.shape}\")\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Error loading processed data: {e}. I should make sure I ran 04_tree_model.ipynb and saved the data.\")\n",
    "    exit() # I'll exit if the data isn't found.\n",
    "\n",
    "# This is my helper function for categorical reconstruction from the last notebook.\n",
    "def reconstruct_category(df, prefix):\n",
    "    \"\"\"\n",
    "    I'm reconstructing a single categorical column from its one-hot encoded dummies.\n",
    "    For example, if I have 'town_bishan', 'town_bedok', etc., and the prefix is 'town_',\n",
    "    I'll create a 'town' column with the values 'bishan', 'bedok', etc.\n",
    "    \"\"\"\n",
    "    category_dummy_cols = [col for col in df.columns if col.startswith(prefix)]\n",
    "    if not category_dummy_cols:\n",
    "        return pd.Series(np.nan, index=df.index, name=prefix.rstrip('_'))\n",
    "\n",
    "    reconstructed_series = df[category_dummy_cols].idxmax(axis=1).str.replace(prefix, '')\n",
    "    return reconstructed_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36a00377",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 2. Model 1: I'll use a Random Forest Regressor. ---\n",
    "print(\"\\n--- Training Random Forest Regressor ---\")\n",
    "rf_r = RandomForestRegressor(\n",
    "    n_estimators=100, # I'm using 100 like before.\n",
    "    max_depth=None,\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "rf_r.fit(X_train, y_train)\n",
    "\n",
    "# I'll evaluate the Random Forest.\n",
    "rf_preds = rf_r.predict(X_test)\n",
    "rf_mae = mean_absolute_error(y_test, rf_preds)\n",
    "rf_rmse = np.sqrt(mean_squared_error(y_test, rf_preds))\n",
    "\n",
    "print(f\"Random Forest MAE: {rf_mae:,.0f} SGD\")\n",
    "print(f\"Random Forest RMSE: {rf_rmse:,.0f} SGD\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be13554",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- I'll create sample weights for the rare classes. ---\n",
    "# I'll initialize all the weights to 1.\n",
    "sample_weights = np.ones(len(X_train))\n",
    "\n",
    "# I need to identify the Executive and Multi-Generation flats in the training set.\n",
    "# These are the one-hot encoded columns in X_train.\n",
    "executive_mask = X_train['flat_type_executive'] == True\n",
    "multi_gen_mask = X_train['flat_type_multi_generation'] == True\n",
    "\n",
    "# I'll assign a higher weight to them, like 2x the normal weight.\n",
    "sample_weights[executive_mask] = 2.0\n",
    "sample_weights[multi_gen_mask] = 2.0\n",
    "\n",
    "print(f\"Assigned higher weights to {executive_mask.sum() + multi_gen_mask.sum()} rare class flats.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f8654a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 3. Model 2: I'll use a LightGBM Regressor. ---\n",
    "print(\"\\n--- Training LightGBM Regressor ---\")\n",
    "lgbm_r = lgb.LGBMRegressor(\n",
    "    n_estimators=10000, # LightGBM is fast, so I can use a lot of estimators.\n",
    "    learning_rate=0.05,\n",
    "    num_leaves=31, # This is the default, but I can tune it.\n",
    "    n_jobs=-1,\n",
    "    random_state=42,\n",
    "    colsample_bytree=0.7, # I'll use feature subsampling.\n",
    "    subsample=0.7,        # And data subsampling.\n",
    "    reg_alpha=0.1,        # L1 regularization.\n",
    "    reg_lambda=0.1,       # L2 regularization.\n",
    ")\n",
    "lgbm_r.fit(X_train, y_train, sample_weight=sample_weights)\n",
    "\n",
    "# I'll evaluate the LightGBM.\n",
    "lgbm_preds = lgbm_r.predict(X_test)\n",
    "lgbm_mae = mean_absolute_error(y_test, lgbm_preds)\n",
    "lgbm_rmse = np.sqrt(mean_squared_error(y_test, lgbm_preds))\n",
    "\n",
    "print(f\"LightGBM MAE: {lgbm_mae:,.0f} SGD\")\n",
    "print(f\"LightGBM RMSE: {lgbm_rmse:,.0f} SGD\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a35eb4f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 4. I'll compare the models. ---\n",
    "print(\"\\n--- Model Comparison Summary ---\")\n",
    "print(f\"Random Forest MAE: {rf_mae:,.0f} SGD\")\n",
    "print(f\"LightGBM MAE:    {lgbm_mae:,.0f} SGD\")\n",
    "\n",
    "if lgbm_mae < rf_mae:\n",
    "    print(f\"\\nLightGBM performed better by {rf_mae - lgbm_mae:,.0f} SGD MAE!\")\n",
    "    best_model_name = \"LightGBM\"\n",
    "    best_model = lgbm_r\n",
    "    best_preds = lgbm_preds\n",
    "    best_mae = lgbm_mae\n",
    "    best_rmse = lgbm_rmse # I added this line.\n",
    "else:\n",
    "    print(f\"\\nRandom Forest performed better by {lgbm_mae - rf_mae:,.0f} SGD MAE!\")\n",
    "    best_model_name = \"Random Forest\"\n",
    "    best_model = rf_r\n",
    "    best_preds = rf_preds\n",
    "    best_mae = rf_mae\n",
    "    best_rmse = rf_rmse # And this one.\n",
    "\n",
    "print(f\"\\nProceeding with error analysis for the {best_model_name} model.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a038ed4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 5. I'll do some error analysis on the best model. ---\n",
    "\n",
    "# I'll attach the predictions and error to my test frame for a closer look.\n",
    "test_df_analysis = X_test.copy()\n",
    "test_df_analysis[\"actual\"] = y_test.values\n",
    "test_df_analysis[\"predicted\"] = best_preds\n",
    "test_df_analysis[\"abs_error\"] = (test_df_analysis[\"actual\"] - test_df_analysis[\"predicted\"]).abs()\n",
    "\n",
    "# I'll reconstruct the 'town' and 'flat_type' columns from the one-hot encoded columns.\n",
    "test_df_analysis['town'] = reconstruct_category(test_df_analysis, 'town_')\n",
    "test_df_analysis['flat_type'] = reconstruct_category(test_df_analysis, 'flat_type_')\n",
    "\n",
    "\n",
    "# 5.1.2 I'll look at the worst 20 rows.\n",
    "worst20 = test_df_analysis.sort_values(\"abs_error\", ascending=False).head(20)\n",
    "display_cols = [\"actual\", \"predicted\", \"abs_error\",\n",
    "                \"sale_year\", \"town\", \"flat_type\", \"floor_area_sqm\", \"lease_remaining_years\"]\n",
    "print(f\"\\n--- Top-20 worst absolute errors for {best_model_name} ---\")\n",
    "print(worst20[display_cols].to_string())\n",
    "\n",
    "\n",
    "# 5.1.3 I'll slice the errors by town and flat_type.\n",
    "def mae_by(group_col, df_to_analyze):\n",
    "    return (df_to_analyze\n",
    "            .assign(error=df_to_analyze[\"abs_error\"])\n",
    "            .groupby(group_col)[\"error\"]\n",
    "            .mean()\n",
    "            .sort_values(ascending=False)\n",
    "            .head(10))\n",
    "\n",
    "print(f\"\\n--- Worst towns by MAE for {best_model_name} ---\")\n",
    "# I need to make sure the 'town' column has no NaNs.\n",
    "print(mae_by(\"town\", test_df_analysis.dropna(subset=['town'])))\n",
    "\n",
    "print(f\"\\n--- Worst flat_types by MAE for {best_model_name} ---\")\n",
    "# And the 'flat_type' column too.\n",
    "print(mae_by(\"flat_type\", test_df_analysis.dropna(subset=['flat_type'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "868d7222",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 6. I'll save the best model and its metrics. ---\n",
    "(PROJECT_ROOT / \"models\").mkdir(parents=True, exist_ok=True)\n",
    "joblib.dump(best_model, PROJECT_ROOT / f\"models/{best_model_name.lower().replace(' ', '_')}_comparison_model.joblib\")\n",
    "print(f\"\\nBest model ({best_model_name}) saved successfully.\")\n",
    "\n",
    "feature_list = X_train.columns.tolist()\n",
    "joblib.dump(feature_list, PROJECT_ROOT / \"models/feature_list.joblib\")\n",
    "print(\"Feature list saved successfully.\")\n",
    "\n",
    "(PROJECT_ROOT / \"reports\").mkdir(parents=True, exist_ok=True)\n",
    "metrics_df = pd.DataFrame([{'model': best_model_name, 'MAE': best_mae, 'RMSE': best_rmse}])\n",
    "metrics_df.to_csv(PROJECT_ROOT / \"reports/model_comparison_metrics.csv\", index=False)\n",
    "print(\"Model comparison metrics saved.\")\n",
    "\n",
    "print(\"\\nNotebook 06_model_comparison.ipynb execution complete.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hdb-predictor-app-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
